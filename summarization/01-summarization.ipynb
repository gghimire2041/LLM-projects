{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statement of the Problem/Requirements\n",
    "1) Write an application to summarize the given text\n",
    "2) The summary should be free of industrial jargons\n",
    "3) Need to use any LLM from OpenAI\n",
    "4) Do not expose the OpenAI API Key\n",
    "5) Prepare a well documented jupyter notebook as well as script file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "import openai\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OpenAI Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERSONA_PROMPT = \"You are to act as an expert project manager.\"\n",
    "\n",
    "SECTION_PROMPT = f\"{PERSONA_PROMPT} Paraphrase each thought into bullet point statements. Do not include an intro or conclusion.\"\n",
    "TOPIC_PROMPT = f\"{PERSONA_PROMPT} Separate the following notes into sections by topic. Do not change the wording or order of notes.\"\n",
    "SUMMARY_PROMPT = f\"{PERSONA_PROMPT} Summarize the following meeting notes in Key Takeaways and Action Items. Key Takeaways and Action Items should not repeat each other.\"\n",
    "\n",
    "TEMPERATURE = 0\n",
    "OVERLAP = 50\n",
    "SECTION_RESPONSE_MAX_TOKENS = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up OpenAI API credentials and model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\", None)\n",
    "if API_KEY is None:\n",
    "    print(\"Error: OPENAI_ORG_ID and OPENAI_API_KEY environment variables must be set.\")\n",
    "    sys.exit(1)\n",
    "openai.api_key = API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gpt-3.5-turbo\"\n",
    "SYSTEM_PROMPT = \"You are a helpful assistant.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_text(input_file):\n",
    "    try:\n",
    "        with open(input_file, 'r') as f:\n",
    "            text = f.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: file '{input_file}' not found.\")\n",
    "        sys.exit(1)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting for processing the input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_arguments():\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Process text file and create summaries using OpenAI.\")\n",
    "    parser.add_argument(\"input_file\", help=\"The input text file to process.\")\n",
    "    parser.add_argument(\"-o\", \"--output_file\", nargs=\"?\",\n",
    "                        help=\"The output file where the results will be saved. If omitted, the output file will be named the same as the input file, but appended with '_output' and always have a '.txt' extension.\")\n",
    "    parser.add_argument(\"-j\", \"--jargon_file\", nargs=\"?\", const=\"jargon.txt\",\n",
    "                        help=\"Replace jargon terms before processing text. Will check for jargon.txt in the current working directory unless another file location is specified.\")\n",
    "    parser.add_argument(\"-t\", \"--topics\", nargs=\"?\", const=\"prompt\",\n",
    "                        help=\"Sort notes by topic. Provide a comma-separated list of topics or use 'auto' to automatically generate topics. Default is 'prompt' which will ask for the list at runtime.\")\n",
    "    parser.add_argument(\"-s\", \"--summary\", action=\"store_true\",\n",
    "                        help=\"Generate a summary of the notes and include in the output file.\")\n",
    "    return parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
